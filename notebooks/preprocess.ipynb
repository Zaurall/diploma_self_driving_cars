{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba045145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tqdm import tqdm\n",
    "# from pandarallel import pandarallel\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bfca6c-5786-4405-a05d-a49604cee084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "374748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(files):\n",
    "    dfs = process_map(pd.read_csv, files, max_workers=24, chunksize=100)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "454ccc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f52de37797dc4f7487a98c26c16dfcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train_path = Path(\"../data/train\")\n",
    "train_path = Path(\"../data/train/TOYOTA_RAV4_2019\")\n",
    "# test_path = Path(\"../data/test\")\n",
    "\n",
    "train_files = list(train_path.glob(\"**/*.csv\"))\n",
    "# test_files = list(test_path.glob(\"*.csv\"))\n",
    "\n",
    "train_df, train_dfs = get_samples(train_files)\n",
    "# test_df, test_dfs = get_samples(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8207fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['roll', 'aEgo', 'vEgo', 'latAccelSteeringAngle', 'steeringAngleDeg']\n",
    "\n",
    "for i in range(len(train_dfs)):\n",
    "    train_dfs[i] = train_dfs[i][save_columns].rename(columns={\n",
    "        'latAccelSteeringAngle': 'targetLateralAcceleration',\n",
    "        'steeringAngleDeg': 'steerCommand'\n",
    "    })\n",
    "    \n",
    "train_df = train_df[save_columns].rename(columns={\n",
    "    'latAccelSteeringAngle': 'targetLateralAcceleration',\n",
    "    'steeringAngleDeg': 'steerCommand'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ad4ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting scalers: 100%|██████████| 4/4 [00:00<00:00, 12.27it/s]\n",
      "Scaling training data: 100%|██████████| 25000/25000 [02:17<00:00, 181.52it/s]\n"
     ]
    }
   ],
   "source": [
    "scalers = {\n",
    "    'aEgo': StandardScaler(),\n",
    "    'vEgo': StandardScaler(),\n",
    "    'roll': StandardScaler(),\n",
    "    'targetLateralAcceleration': StandardScaler() # RobustScaler() \n",
    "}\n",
    "\n",
    "def scale_steering_by_first_10_seconds(df, steering_col='steerCommand'):\n",
    "    first_10 = df.iloc[:100]\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(first_10[[steering_col]])\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[steering_col] = scaler.transform(df[[steering_col]])\n",
    "    return df_scaled\n",
    "\n",
    "for col, scaler in tqdm(scalers.items(), desc=\"Fitting scalers\"):\n",
    "    scaler.fit(train_df[[col]])\n",
    "    \n",
    "train_scaled = []\n",
    "for df in tqdm(train_dfs, desc=\"Scaling training data\"):\n",
    "    df_scaled = df.copy()\n",
    "    for col, scaler in scalers.items():\n",
    "        df_scaled[col] = scaler.transform(df[[col]])\n",
    "    df_scaled = scale_steering_by_first_10_seconds(df_scaled)\n",
    "    train_scaled.append(df_scaled)\n",
    "\n",
    "# test_scaled = []\n",
    "# for df in tqdm(test_dfs):\n",
    "#     df_scaled = df.copy()\n",
    "#     for col, scaler in scalers.items():\n",
    "#         df_scaled[col] = scaler.transform(df[[col]])\n",
    "#     df_scaled = scale_steering_by_first_10_seconds(df_scaled)\n",
    "#     test_scaled.append(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9fe6fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll</th>\n",
       "      <th>aEgo</th>\n",
       "      <th>vEgo</th>\n",
       "      <th>targetLateralAcceleration</th>\n",
       "      <th>steerCommand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.329384</td>\n",
       "      <td>-1.576942</td>\n",
       "      <td>-1.819684</td>\n",
       "      <td>-0.024133</td>\n",
       "      <td>0.540984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.323101</td>\n",
       "      <td>-1.006901</td>\n",
       "      <td>-1.823530</td>\n",
       "      <td>-0.034965</td>\n",
       "      <td>0.645742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.316817</td>\n",
       "      <td>-0.687486</td>\n",
       "      <td>-1.826262</td>\n",
       "      <td>-0.088302</td>\n",
       "      <td>1.141273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.310533</td>\n",
       "      <td>-0.226573</td>\n",
       "      <td>-1.826059</td>\n",
       "      <td>-0.133354</td>\n",
       "      <td>1.556987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.315720</td>\n",
       "      <td>-0.557453</td>\n",
       "      <td>-1.829611</td>\n",
       "      <td>-0.134020</td>\n",
       "      <td>1.577743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roll      aEgo      vEgo  targetLateralAcceleration  steerCommand\n",
       "0 -0.329384 -1.576942 -1.819684                  -0.024133      0.540984\n",
       "1 -0.323101 -1.006901 -1.823530                  -0.034965      0.645742\n",
       "2 -0.316817 -0.687486 -1.826262                  -0.088302      1.141273\n",
       "3 -0.310533 -0.226573 -1.826059                  -0.133354      1.556987\n",
       "4 -0.315720 -0.557453 -1.829611                  -0.134020      1.577743"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61efcb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_scaled[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cda67df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4c71e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Model ---\n",
    "class LstmEncoderDecoder(nn.Module):\n",
    "    def __init__(self, physics_input_size, control_input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.physics_encoder = nn.LSTM(physics_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.control_encoder = nn.LSTM(control_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(control_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)  # Predict targetLateralAcceleration\n",
    "\n",
    "    def forward(self, input_physics, input_control_sequence):\n",
    "        _, (hidden_phsc, cell_phsc) = self.physics_encoder(input_physics)\n",
    "        _, (hidden_ctrl, cell_ctrl) = self.control_encoder(input_control_sequence)\n",
    "        \n",
    "        hidden_enc = (hidden_phsc + hidden_ctrl) / 2\n",
    "        cell_enc = (cell_phsc + cell_ctrl) / 2\n",
    "        \n",
    "        decoder_output, _ = self.decoder(input_control_sequence, (hidden_enc, cell_enc))\n",
    "        \n",
    "        output = self.fc_out(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98814faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, dfs, seq_len=20):\n",
    "        self.samples = []\n",
    "        for df in dfs:\n",
    "            arr = df[['roll', 'aEgo', 'vEgo', 'targetLateralAcceleration', 'steerCommand']].values\n",
    "            for i in range(len(arr) - seq_len - 1):\n",
    "                physics_input = arr[i:i+seq_len, :3]\n",
    "                control_input = arr[i:i+seq_len, 3:]\n",
    "                y = arr[i+1:i+seq_len+1, 4]    # target: next steerCommand\n",
    "                self.samples.append((physics_input, control_input, y.reshape(-1, 1)))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        physics_input, control_input, y = self.samples[idx]\n",
    "        return (torch.tensor(physics_input, dtype=torch.float32),\n",
    "                torch.tensor(control_input, dtype=torch.float32),\n",
    "                torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "def train_val_split(dfs, val_ratio=0.2, seed=42):\n",
    "    \"\"\"Split list of dataframes into training and validation sets\"\"\"\n",
    "    random.seed(seed)\n",
    "    n_val = int(len(dfs) * val_ratio)\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    indices = list(range(len(dfs)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Split into train and validation\n",
    "    val_indices = indices[:n_val]\n",
    "    train_indices = indices[n_val:]\n",
    "    \n",
    "    train_dfs = [dfs[i] for i in train_indices]\n",
    "    val_dfs = [dfs[i] for i in val_indices]\n",
    "    \n",
    "    return train_dfs, val_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de937960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_save_path, train_dfs, val_dfs=None, num_epochs=5, batch_size=64, seq_len=20,\n",
    "                lr=1e-3, hidden_size=128, num_layers=4):\n",
    "    train_dataset = DrivingDataset(train_dfs, seq_len=seq_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    if val_dfs:\n",
    "        val_dataset = DrivingDataset(val_dfs, seq_len=seq_len)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = LstmEncoderDecoder(\n",
    "        physics_input_size=3,\n",
    "        control_input_size=2,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for physics_input, control_input, y in tqdm(train_loader):\n",
    "            physics_input = physics_input.to(DEVICE)\n",
    "            control_input = control_input.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(physics_input, control_input)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        if val_dfs:\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for physics_input, control_input, y in val_loader:\n",
    "                    physics_input = physics_input.to(DEVICE)\n",
    "                    control_input = control_input.to(DEVICE)\n",
    "                    y = y.to(DEVICE)\n",
    "                    \n",
    "                    out = model(physics_input, control_input)\n",
    "                    loss = criterion(out, y)\n",
    "                    total_val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), f\"{model_save_path}/lstm_best_model.pt\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eedb93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 180772/180772 [16:57<00:00, 177.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/33 | Train Loss: 338085317.0849 | Val Loss: 6500349.5577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 42286/180772 [03:58<12:45, 180.82it/s]"
     ]
    }
   ],
   "source": [
    "train_split, val_split = train_val_split(train_scaled)\n",
    "model_version = 'base_v1_full_dataset_10_epochs'\n",
    "model_save_path = f\"../models/{model_version}\"\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "model = train_model(model_save_path, train_split, val_split, num_epochs=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a7d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f\"{model_save_path}/lstm_lataccel.pt\")\n",
    "for name, scaler in scalers.items():\n",
    "    if hasattr(scaler, 'feature_names_in_'):\n",
    "        scaler.feature_names_in_ = None\n",
    "\n",
    "with open(f\"{model_save_path}/scalers.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb8ed93-3fb8-4186-aeaa-f4fdb7708b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561e085-194f-48fa-8276-1f5272fa6edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
