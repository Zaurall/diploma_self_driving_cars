{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba045145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from tqdm import tqdm\n",
    "# from pandarallel import pandarallel\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "\n",
    "# pandarallel.initialize(progress_bar=True)\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7bfca6c-5786-4405-a05d-a49604cee084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "374748a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples(files):\n",
    "    dfs = process_map(pd.read_csv, files, max_workers=24, chunksize=100)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df, dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "454ccc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339011e1eb6b4222b2e117cf42fdc6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/832798 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883deb38a3f54acab128affe6249fc64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_path = Path(\"../data/train\")\n",
    "test_path = Path(\"../data/test\")\n",
    "\n",
    "train_files = list(train_path.glob(\"**/*.csv\"))\n",
    "test_files = list(test_path.glob(\"*.csv\"))\n",
    "\n",
    "train_df, train_dfs = get_samples(train_files)\n",
    "test_df, test_dfs = get_samples(test_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8207fa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_columns = ['roll', 'aEgo', 'vEgo', 'latAccelSteeringAngle', 'steeringAngleDeg']\n",
    "\n",
    "for i in range(len(train_dfs)):\n",
    "    train_dfs[i] = train_dfs[i][save_columns].rename(columns={\n",
    "        'latAccelSteeringAngle': 'targetLateralAcceleration',\n",
    "        'steeringAngleDeg': 'steerCommand'\n",
    "    })\n",
    "    \n",
    "train_df = train_df[save_columns].rename(columns={\n",
    "    'latAccelSteeringAngle': 'targetLateralAcceleration',\n",
    "    'steeringAngleDeg': 'steerCommand'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34ad4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "scalers = {\n",
    "    'aEgo': StandardScaler(),\n",
    "    'vEgo': StandardScaler(),\n",
    "    'roll': StandardScaler(),\n",
    "    'targetLateralAcceleration': StandardScaler() # RobustScaler() \n",
    "}\n",
    "\n",
    "def scale_steering_by_first_10_seconds(df, steering_col='steerCommand'):\n",
    "    first_10 = df.iloc[:100]\n",
    "    scaler = RobustScaler()\n",
    "    scaler.fit(first_10[[steering_col]])\n",
    "    df_scaled = df.copy()\n",
    "    df_scaled[steering_col] = scaler.transform(df[[steering_col]])\n",
    "    return df_scaled\n",
    "\n",
    "for col, scaler in tqdm(scalers.items(), desc=\"Fitting scalers\"):\n",
    "    scaler.fit(train_df[[col]])\n",
    "    \n",
    "train_scaled = []\n",
    "for df in tqdm(train_dfs, desc=\"Scaling training data\"):\n",
    "    df_scaled = df.copy()\n",
    "    for col, scaler in scalers.items():\n",
    "        df_scaled[col] = scaler.transform(df[[col]])\n",
    "    df_scaled = scale_steering_by_first_10_seconds(df_scaled)\n",
    "    train_scaled.append(df_scaled)\n",
    "\n",
    "test_scaled = []\n",
    "for df in tqdm(test_dfs):\n",
    "    df_scaled = df.copy()\n",
    "    for col, scaler in scalers.items():\n",
    "        df_scaled[col] = scaler.transform(df[[col]])\n",
    "    df_scaled = scale_steering_by_first_10_seconds(df_scaled)\n",
    "    test_scaled.append(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fe6fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roll</th>\n",
       "      <th>aEgo</th>\n",
       "      <th>vEgo</th>\n",
       "      <th>targetLateralAcceleration</th>\n",
       "      <th>steerCommand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.795990</td>\n",
       "      <td>0.255430</td>\n",
       "      <td>-0.217987</td>\n",
       "      <td>0.198525</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.830347</td>\n",
       "      <td>0.283653</td>\n",
       "      <td>-0.216903</td>\n",
       "      <td>0.199554</td>\n",
       "      <td>-0.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.864705</td>\n",
       "      <td>0.288052</td>\n",
       "      <td>-0.215774</td>\n",
       "      <td>0.144675</td>\n",
       "      <td>-0.062679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.899062</td>\n",
       "      <td>0.268569</td>\n",
       "      <td>-0.215247</td>\n",
       "      <td>0.095632</td>\n",
       "      <td>0.062037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.924962</td>\n",
       "      <td>0.694610</td>\n",
       "      <td>-0.211312</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>0.124887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       roll      aEgo      vEgo  targetLateralAcceleration  steerCommand\n",
       "0 -0.795990  0.255430 -0.217987                   0.198525     -0.187500\n",
       "1 -0.830347  0.283653 -0.216903                   0.199554     -0.187500\n",
       "2 -0.864705  0.288052 -0.215774                   0.144675     -0.062679\n",
       "3 -0.899062  0.268569 -0.215247                   0.095632      0.062037\n",
       "4 -0.924962  0.694610 -0.211312                   0.072798      0.124887"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61efcb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>vEgo</th>\n",
       "      <th>aEgo</th>\n",
       "      <th>roll</th>\n",
       "      <th>targetLateralAcceleration</th>\n",
       "      <th>steerCommand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.598870</td>\n",
       "      <td>0.067468</td>\n",
       "      <td>0.596711</td>\n",
       "      <td>-0.076423</td>\n",
       "      <td>-0.439803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>1.598888</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.594146</td>\n",
       "      <td>-0.025446</td>\n",
       "      <td>-0.523350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>1.598994</td>\n",
       "      <td>-0.019195</td>\n",
       "      <td>0.591581</td>\n",
       "      <td>0.009397</td>\n",
       "      <td>-0.471967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1.599457</td>\n",
       "      <td>0.067695</td>\n",
       "      <td>0.586913</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>-0.496606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4</td>\n",
       "      <td>1.600724</td>\n",
       "      <td>0.216295</td>\n",
       "      <td>0.580619</td>\n",
       "      <td>0.021605</td>\n",
       "      <td>-0.649739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     t      vEgo      aEgo      roll  targetLateralAcceleration  steerCommand\n",
       "0  0.0  1.598870  0.067468  0.596711                  -0.076423     -0.439803\n",
       "1  0.1  1.598888  0.012449  0.594146                  -0.025446     -0.523350\n",
       "2  0.2  1.598994 -0.019195  0.591581                   0.009397     -0.471967\n",
       "3  0.3  1.599457  0.067695  0.586913                   0.008378     -0.496606\n",
       "4  0.4  1.600724  0.216295  0.580619                   0.021605     -0.649739"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scaled[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda67df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e4c71e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# --- Model ---\n",
    "class LstmEncoderDecoder(nn.Module):\n",
    "    def __init__(self, physics_input_size, control_input_size, hidden_size, num_layers, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.physics_encoder = nn.LSTM(physics_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.control_encoder = nn.LSTM(control_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.decoder = nn.LSTM(control_input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)  # Predict targetLateralAcceleration\n",
    "\n",
    "    def forward(self, input_physics, input_control_sequence):\n",
    "        _, (hidden_phsc, cell_phsc) = self.physics_encoder(input_physics)\n",
    "        _, (hidden_ctrl, cell_ctrl) = self.control_encoder(input_control_sequence)\n",
    "        \n",
    "        hidden_enc = (hidden_phsc + hidden_ctrl) / 2\n",
    "        cell_enc = (cell_phsc + cell_ctrl) / 2\n",
    "        \n",
    "        decoder_output, _ = self.decoder(input_control_sequence, (hidden_enc, cell_enc))\n",
    "        \n",
    "        output = self.fc_out(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98814faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrivingDataset(Dataset):\n",
    "    def __init__(self, dfs, seq_len=20):\n",
    "        self.samples = []\n",
    "        for df in dfs:\n",
    "            arr = df[['roll', 'aEgo', 'vEgo', 'targetLateralAcceleration', 'steerCommand']].values\n",
    "            for i in range(len(arr) - seq_len - 1):\n",
    "                physics_input = arr[i:i+seq_len, :3]\n",
    "                control_input = arr[i:i+seq_len, 3:]\n",
    "                y = arr[i+1:i+seq_len+1, 4]    # target: next steerCommand\n",
    "                self.samples.append((physics_input, control_input, y.reshape(-1, 1)))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        physics_input, control_input, y = self.samples[idx]\n",
    "        return (torch.tensor(physics_input, dtype=torch.float32),\n",
    "                torch.tensor(control_input, dtype=torch.float32),\n",
    "                torch.tensor(y, dtype=torch.float32))\n",
    "\n",
    "def train_val_split(dfs, val_ratio=0.2, seed=42):\n",
    "    \"\"\"Split list of dataframes into training and validation sets\"\"\"\n",
    "    random.seed(seed)\n",
    "    n_val = int(len(dfs) * val_ratio)\n",
    "    \n",
    "    # Shuffle the indices\n",
    "    indices = list(range(len(dfs)))\n",
    "    random.shuffle(indices)\n",
    "    \n",
    "    # Split into train and validation\n",
    "    val_indices = indices[:n_val]\n",
    "    train_indices = indices[n_val:]\n",
    "    \n",
    "    train_dfs = [dfs[i] for i in train_indices]\n",
    "    val_dfs = [dfs[i] for i in val_indices]\n",
    "    \n",
    "    return train_dfs, val_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de937960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dfs, val_dfs=None, num_epochs=5, batch_size=64, seq_len=20,\n",
    "                lr=1e-3, hidden_size=128, num_layers=4):\n",
    "    train_dataset = DrivingDataset(train_dfs, seq_len=seq_len)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    if val_dfs:\n",
    "        val_dataset = DrivingDataset(val_dfs, seq_len=seq_len)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = LstmEncoderDecoder(\n",
    "        physics_input_size=3,\n",
    "        control_input_size=2,\n",
    "        hidden_size=hidden_size,\n",
    "        num_layers=num_layers\n",
    "    ).to(DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        \n",
    "        for physics_input, control_input, y in tqdm(train_loader):\n",
    "            physics_input = physics_input.to(DEVICE)\n",
    "            control_input = control_input.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            out = model(physics_input, control_input)\n",
    "            loss = criterion(out, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_train_loss += loss.item()\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        if val_dfs:\n",
    "            model.eval()\n",
    "            total_val_loss = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for physics_input, control_input, y in val_loader:\n",
    "                    physics_input = physics_input.to(DEVICE)\n",
    "                    control_input = control_input.to(DEVICE)\n",
    "                    y = y.to(DEVICE)\n",
    "                    \n",
    "                    out = model(physics_input, control_input)\n",
    "                    loss = criterion(out, y)\n",
    "                    total_val_loss += loss.item()\n",
    "            \n",
    "            avg_val_loss = total_val_loss / len(val_loader)\n",
    "            \n",
    "            # Save best model\n",
    "            if avg_val_loss < best_val_loss:\n",
    "                best_val_loss = avg_val_loss\n",
    "                torch.save(model.state_dict(), \"../models/lstm_best_model.pt\")\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eedb93ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:22<00:00, 178.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 | Train Loss: 71.1661 | Val Loss: 694.7622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:26<00:00, 172.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 | Train Loss: 34.0143 | Val Loss: 616.6923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:21<00:00, 178.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 | Train Loss: 27.0678 | Val Loss: 659.3102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:25<00:00, 173.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 | Train Loss: 23.0977 | Val Loss: 627.4575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:26<00:00, 172.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 | Train Loss: 23.2784 | Val Loss: 540.1553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:24<00:00, 175.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 | Train Loss: 22.1250 | Val Loss: 526.4878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:25<00:00, 174.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 | Train Loss: 18.4108 | Val Loss: 653.5698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:22<00:00, 177.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 | Train Loss: 19.1502 | Val Loss: 489.5398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:21<00:00, 178.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 | Train Loss: 17.5664 | Val Loss: 502.3697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25309/25309 [02:25<00:00, 173.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 | Train Loss: 14.4830 | Val Loss: 474.0756\n"
     ]
    }
   ],
   "source": [
    "train_split, val_split = train_val_split(train_scaled)\n",
    "model_version = 'base_v1_full_dataset_10_epochs'\n",
    "model = train_model(train_split, val_split, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a7d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"../models//v1/lstm_lataccel.pt\")\n",
    "for name, scaler in scalers.items():\n",
    "    if hasattr(scaler, 'feature_names_in_'):\n",
    "        scaler.feature_names_in_ = None\n",
    "\n",
    "with open(\"../models/scalers.pkl\", \"wb\") as f:\n",
    "    pickle.dump(scalers, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adb8ed93-3fb8-4186-aeaa-f4fdb7708b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d561e085-194f-48fa-8276-1f5272fa6edc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
